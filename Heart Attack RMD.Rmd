---
title: "Heart Failure Analysis"
author: "Adrian Tores"
date: "2024-02-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r}
#TEST

library(tidyverse)     # For data manipulation and visualization
library(caret)         # For machine learning tasks
library(reticulate)    # For hyperparameter optimization
library(RcppRoll)      # For fast rolling functions
library(gridExtra)     # For arranging plots
library(ggplot2)       # Load the ggplot2 package
library(tidyverse)    # For data manipulation and visualization
library(dplyr)
library(caTools)

# Specify the file path using forward slashes or double backslashes
file_path <- "C:/Users/adria/Downloads/Introduction to Data Science/Project/2022/heart_2022_no_nans.csv"

# Read the CSV file and assign it to a variable
data <- read.csv(file_path)

# Check the structure of the data
```


```{r}
#Taking a look at the data
str(data)
summary(data)
```


```{r, fig.width=8,fig.height=3}
# Remove "HadHeartAttack" column
data_without_had_heart_attack <- data[, !names(data) == "HadHeartAttack"]

# Count "Yes" for each column
yes_counts <- colSums(data_without_had_heart_attack == "Yes")

# Extract top 15 columns with highest "Yes" counts
top_15_columns <- names(sort(yes_counts, decreasing = TRUE)[1:15])
top_15_counts <- yes_counts[top_15_columns]


# Get top 15 variables and their counts
top_15_variables <- names(top_15_counts)
top_15_counts <- unname(top_15_counts)

# Generate random colors for each bar
bar_colors <- rainbow(length(top_15_counts))

plot_data <- data.frame(variable = factor(top_15_variables, levels = rev(top_15_variables)),
                        count = top_15_counts)

# Plot using ggplot2
ggplot(plot_data, aes(x = count, y = variable)) +
  geom_col(fill = rainbow(length(top_15_counts))) +
  scale_x_continuous(labels = scales::comma) +
  labs(x = "Total", y = NULL) +
  theme_minimal()

# Find the most common age group of users who have had heart attacks
most_common_age_group <- names(sort(table(data$AgeCategory[data$HadHeartAttack == "Yes"]), decreasing = TRUE))[1]
cat("Most common Age group who have had heart attacks:", most_common_age_group, "\n")

```


```{r, fig.width=8,fig.height=3}

# Filter the data for only those who had a heart attack
heart_attack_data <- subset(data, HadHeartAttack == "Yes")

# Create a data frame with all possible levels of AgeCategory
all_age_categories <- data.frame(AgeCategory = unique(data$AgeCategory))

# Get the table of counts for individuals who had a heart attack
heart_attack_counts <- as.data.frame(table(heart_attack_data$AgeCategory))
names(heart_attack_counts) <- c("AgeCategory", "Freq")  # Rename columns

# Merge the data frames
plot_data <- merge(all_age_categories, heart_attack_counts, by = "AgeCategory", all.x = TRUE)

# Fill missing counts with 0
plot_data$Freq[is.na(plot_data$Freq)] <- 0

# Ensure AgeCategory is a factor
plot_data$AgeCategory <- factor(plot_data$AgeCategory, levels = unique(plot_data$AgeCategory))

# Plot using ggplot2 with the adjustments
ggplot(plot_data, aes(x = Freq, y = AgeCategory)) +
  geom_col(fill = "skyblue") +
  labs(x = "Count", y = "Age Category", title = "Had Heart Attack by Age Category") +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10)) 


# Calculate percentage of users who have and have not had heart attacks
percentage_NoHeartAttack <- round(mean(data$HadHeartAttack == "No") * 100, 2)
percentage_HeartAttack <- round(mean(data$HadHeartAttack == "Yes") * 100, 2)
cat("Percentage of 'No' in HadHeartAttack column:", percentage_NoHeartAttack, "%\n")
cat("Percentage of 'Yes' in HadHeartAttack column:", percentage_HeartAttack, "%\n")
```


```{r, fig.width=8,fig.height=3}
# Plot distribution of HadHeartAttack responses using a pie chart
pie(c(percentage_NoHeartAttack, percentage_HeartAttack),
    labels = c(paste("Have not Had Heart Attack:", percentage_NoHeartAttack, "%"),
               paste("Have had Heart Attack:", percentage_HeartAttack, "%")),
    main = "Distribution of HadHeartAttack Responses",
    col = c("orange", "brown"))

# Calculate total number of users who have and have not had heart attacks
total_NoHeartAttack <- sum(data$HadHeartAttack == "No")
total_HeartAttack <- sum(data$HadHeartAttack == "Yes")
cat("Total number of 'No' in HadHeartAttack column:", total_NoHeartAttack, "\n")
cat("Total number of 'Yes' in HadHeartAttack column:", total_HeartAttack, "\n")

# Plot frequency bar plot for HadHeartAttack
barplot(table(data$HadHeartAttack),
        col = c("yellow", "black"),
        main = "Have not had Heart Attack Vs Have had Heart Attack",
        xlab = "HadHeartAttack",
        ylab = "Frequency",
        legend = c("Have not had a Heart Attack", "Have had a Heart Attack"))

```


```{r, fig.width=8,fig.height=8}


library(ggplot2)

# Generate some sample data
data <- data.frame(
  RaceEthnicityCategory = c("African American", "Asian", "Hispanic", "White"),
  HadHeartAttack = c(10, 5, 8, 15)
)

ggplot(data, aes(x = RaceEthnicityCategory, y = HadHeartAttack, fill = RaceEthnicityCategory)) +
  geom_bar(stat = "identity") +
  labs(title = "Heart Attack By Race", x = "Race", y = "HadHeartAttack") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(size = 12, angle = 45, hjust = 1), # Adjust x-axis text size and angle
    axis.text.y = element_text(size = 12), # Adjust y-axis text size
    plot.title = element_text(size = 16, face = "bold"), # Adjust title text size and style
    axis.title = element_text(size = 14), # Adjust axis title size
    legend.text = element_text(size = 12), # Adjust legend text size
    legend.title = element_text(size = 14) # Adjust legend title size
  )


```


```{r}

# Read the CSV file and assign it to a variable
data <- read.csv(file_path)

# Create a data frame for the counts of each category
health_counts <- data %>%
  count(GeneralHealth)

# Plotting
ggplot(health_counts, aes(x = GeneralHealth, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "General Health", y = "Counts", title = "Distribution of General Health") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))  # Rotate x-axis labels

 
```

## Including Plots

You can also embed plots, for example:

```{r}
library(corrplot)

# Read the data
data <- read.csv(file_path)

# Select columns
selected_cols <- c(
  "Sex", "GeneralHealth", "PhysicalHealthDays", "MentalHealthDays",
  "PhysicalActivities", "SleepHours", "RemovedTeeth", "HadHeartAttack",
  "HadAngina", "HadStroke", "HadAsthma", "HadSkinCancer", "HadCOPD",
  "HadDepressiveDisorder", "HadKidneyDisease", "HadArthritis", "HadDiabetes",
  "DeafOrHardOfHearing", "BlindOrVisionDifficulty", "DifficultyConcentrating",
  "DifficultyWalking", "DifficultyDressingBathing", "DifficultyErrands",
  "SmokerStatus", "ECigaretteUsage", "ChestScan", "RaceEthnicityCategory",
  "AgeCategory", "HeightInMeters", "WeightInKilograms", "BMI", "AlcoholDrinkers",
  "HIVTesting", "FluVaxLast12", "PneumoVaxEver", "TetanusLast10Tdap", "HighRiskLastYear"
)

# Subset data with selected columns
selected_data <- data[, selected_cols]

# Identify numeric columns
numeric_cols <- sapply(selected_data, is.numeric)

# Filter selected data to numeric columns only
selected_data_numeric <- selected_data[, numeric_cols]

# Compute correlation matrix
correlation_matrix <- cor(selected_data_numeric, use = "complete.obs")

# Plot correlation matrix with colors
corrplot(correlation_matrix, method = "color", type = "upper", order = "hclust", addrect = 4)


#Run step function for best predictor variables to use for linear model only

```
```{r}
selected_cols <- c(
  "Sex", "GeneralHealth", "PhysicalHealthDays", "MentalHealthDays",
  "PhysicalActivities", "SleepHours", "RemovedTeeth", "HadHeartAttack",
  "HadAngina", "HadStroke", "HadAsthma", "HadSkinCancer", "HadCOPD",
  "HadDepressiveDisorder", "HadKidneyDisease", "HadArthritis", "HadDiabetes",
  "DeafOrHardOfHearing", "BlindOrVisionDifficulty", "DifficultyConcentrating",
  "DifficultyWalking", "DifficultyDressingBathing", "DifficultyErrands",
  "SmokerStatus", "ECigaretteUsage", "ChestScan", "RaceEthnicityCategory",
  "AgeCategory", "HeightInMeters", "WeightInKilograms", "BMI", "AlcoholDrinkers",
  "HIVTesting", "FluVaxLast12", "PneumoVaxEver", "TetanusLast10Tdap", "HighRiskLastYear"
)



data_subset <- data[selected_cols]
# Print the dimensions and the first few rows of the selected data
print(dim(data_subset))
head(data_subset)



# Separate columns by data type
cat_cols <- data_subset %>%
  select_if(is.character) %>%
  names()

num_cols <- data_subset %>%
  select_if(is.numeric) %>%
  names()

dbl_cols <- data_subset %>%
  select_if(is.double) %>%
  names()

# Remove state variables from the dataset
data_subset <- data_subset %>%
  select(-starts_with("State"))  # Remove columns starting with "State"

# Data preprocessing
# Convert categorical variables to factors
data_subset <- mutate_if(data_subset, is.character, as.factor)

# Handle missing values if any
data_subset <- na.omit(data_subset)

# Set seed for reproducibility
set.seed(123)  # for reproducibility

# Split data into training and testing sets
train_index <- sample(nrow(data_subset), 0.7 * nrow(data_subset))  # 70% train, 30% test
train_data <- data_subset[train_index, ]
test_data <- data_subset[-train_index, ]


# Model training
# Fit logistic regression model
model <- glm(HadHeartAttack ~ ., data = train_data, family = binomial)

# Model evaluation
# Make predictions on test set
pred_probs <- predict(model, newdata = test_data, type = "response")


# Model evaluation
# Make predictions on test set
pred_probs <- predict(model, newdata = test_data, type = "response")

# Convert probabilities to binary predictions
pred_labels <- ifelse(pred_probs > 0.5, "Yes", "No")

# Convert pred_labels to a factor with levels "No" and "Yes"
pred_labels <- factor(pred_labels, levels = c("No", "Yes"))

# Convert test_data$HadHeartAttack to a factor with the same levels as pred_labels
test_data$HadHeartAttack <- factor(test_data$HadHeartAttack, levels = c("No", "Yes"))

# Evaluate predictions
conf_matrix <- confusionMatrix(data = pred_labels, reference = test_data$HadHeartAttack)
print(conf_matrix)

# Print accuracy
print(paste("Accuracy:", conf_matrix$overall["Accuracy"]))
# Print the lengths of cat_cols, num_cols, and dbl_cols
cat("Length of cat_cols:", length(cat_cols), "\n")
cat("Length of num_cols:", length(num_cols), "\n")
cat("Length of dbl_cols:", length(dbl_cols), "\n")

# Print the total number of columns in data_train
cat("Total number of columns in data_train:", ncol(train_data), "\n")

summary(model)
#03-11-24
#Run tree model as an alternate
#Percent impact for svm and tree model
#varimt()
#Introduce sampling method so that it accounts for excess Nos
#Look for code for lecture on Inferential stats to create new population of better split of "yes" and "no"
```


```{r}
library(caret)
# Determine the minority and majority classes
minority_class <- "Yes"  # Adjust based on your target variable
majority_class <- "No"   # Adjust based on your target variable

# Calculate the number of samples in the minority and majority classes
minority_count <- sum(data_subset$HadHeartAttack == minority_class)
majority_count <- sum(data_subset$HadHeartAttack == majority_class)

# Undersample the majority class to match the number of samples in the minority class
undersampled_majority <- data_subset[data_subset$HadHeartAttack == majority_class, ]
undersampled_majority <- undersampled_majority[sample(nrow(undersampled_majority), minority_count), ]

# Combine the undersampled majority class with all samples from the minority class
balanced_data <- rbind(undersampled_majority, data_subset[data_subset$HadHeartAttack == minority_class, ])

# Shuffle the rows to randomize the order
balanced_data <- balanced_data[sample(nrow(balanced_data)), ]

# Verify the class distribution in the balanced dataset
table(balanced_data$HadHeartAttack)

# Split data into training and testing sets
train_index <- sample(nrow(balanced_data), 0.7 * nrow(balanced_data))  # 70% train, 30% test
train_data <- balanced_data[train_index, ]
test_data <- balanced_data[-train_index, ]

# Model training
# Fit logistic regression model using the training data
model <- glm(HadHeartAttack ~ ., data = train_data, family = binomial)

# Summary of the model
summary(model)


# Model evaluation
# Make predictions on test set
pred_probs <- predict(model, newdata = test_data, type = "response")

# Convert probabilities to binary predictions
pred_labels <- ifelse(pred_probs > 0.5, "Yes", "No")

# Convert pred_labels to a factor with levels "No" and "Yes"
pred_labels <- factor(pred_labels, levels = c("No", "Yes"))

# Convert test_data$HadHeartAttack to a factor with the same levels as pred_labels
test_data$HadHeartAttack <- factor(test_data$HadHeartAttack, levels = c("No", "Yes"))

# Evaluate predictions
conf_matrix <- confusionMatrix(data = pred_labels, reference = test_data$HadHeartAttack)
print(conf_matrix)

# Print accuracy
print(paste("Accuracy:", conf_matrix$overall["Accuracy"]))
# Print the lengths of cat_cols, num_cols, and dbl_cols
cat("Length of cat_cols:", length(cat_cols), "\n")
cat("Length of num_cols:", length(num_cols), "\n")
cat("Length of dbl_cols:", length(dbl_cols), "\n")



```


```{r, fig.width=10,fig.height=5}
# Extract feature importance from the model
feature_importances <- summary(model)$coefficients[-1, "Pr(>|z|)"]

# Create a data frame for feature importance
feature_importance_data <- data.frame(
  feature = names(feature_importances),
  importance = feature_importances
)

# Sort the data frame by importance in descending order
feature_importance_data <- feature_importance_data[order(feature_importance_data$importance, decreasing = TRUE), ]


# Plot Top N Features Only
top_n <- 5 # Adjust this value based on how many top features you want to display

# Create the plot
ggplot(head(feature_importance_data, top_n), aes(x = importance, y = reorder(factor(feature, levels = rev(feature_importance_data$feature)), importance))) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(x = "Importance", y = "Feature", title = paste("Top", top_n, "Feature Importances")) +
  theme_minimal() +
  coord_flip()  # Horizontal bar plot
```
```


```{r}
# Load required library for decision trees
library("rpart")

# Fit decision tree model
tree_model <- rpart(HadHeartAttack ~ ., data = train_data, method = "class")

# Make predictions on the test set
tree_pred <- predict(tree_model, newdata = test_data, type = "class")

# Evaluate predictions
tree_conf_matrix <- confusionMatrix(tree_pred, test_data$HadHeartAttack)
print(tree_conf_matrix)

# Print accuracy
print(paste("Decision Tree Accuracy:", tree_conf_matrix$overall["Accuracy"]))

var_importance <- varImp(tree_model)
print(var_importance)

summary(tree_model)

```


```{r}

# Load required library for SVM

# Fit SVM model
svm_model <- svm(HadHeartAttack ~ ., data = train_data, kernel = "radial")

# Make predictions on the test set
svm_pred <- predict(svm_model, newdata = test_data)

# Evaluate predictions
svm_conf_matrix <- confusionMatrix(svm_pred, test_data$HadHeartAttack)
print(svm_conf_matrix)

# Print accuracy
print(paste("SVM Accuracy:", svm_conf_matrix$overall["Accuracy"]))

```


```{r}
# Example of performing 5-fold cross-validation
set.seed(123)  # for reproducibility
cv <- trainControl(method = "cv", number = 5)
model <- train(HadHeartAttack ~ ., data = train_data, method = "glm", trControl = cv, family = binomial)

# Extract coefficient summary
coef_summary <- summary(model)$coefficients

# Sort coefficients based on p-values
coef_summary <- coef_summary[order(coef_summary[, "Pr(>|z|)"]), ]

# Print variable names and corresponding p-values
print(coef_summary[, "Pr(>|z|)"])
```


```{r}
summary(model$results)
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
